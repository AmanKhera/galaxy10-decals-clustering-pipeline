{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c8f262-5ed4-46af-a0db-47db3e9e0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af978d1e-8bc7-4cb3-8445-3de164637e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_PATH    = \"images/Galaxy10_DECals.h5\"          \n",
    "MODEL_PATH = \"best_model/galaxy_b3_final_BEST_100TP.keras\" #Classifier Model\n",
    "OUT_DIR    = \"artifacts/embeddings\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c232b2-b84d-4885-9eeb-d7cd14984747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768959654.409544    4193 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9513 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-01-20 17:40:54.695023: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "@K.utils.register_keras_serializable()\n",
    "class CastToFloat16(K.layers.Layer):\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, tf.float16)\n",
    "        return preprocess_input(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "#Custom layers must be recreated when loading model\n",
    "clf = tf.keras.models.load_model(MODEL_PATH, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c6f501-f0a4-45c0-8550-342f15557a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an embedding output:\n",
    "embed_output = clf.layers[-2].output  #usually the layer right before the final Dense/Softmax\n",
    "encoder = tf.keras.Model(inputs=clf.input, outputs=embed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5700ab6b-d95b-4591-b783-dd8538df537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (256, 256)\n",
    "BATCH = 48\n",
    "\n",
    "def preprocess_batch(x_uint8):\n",
    "    x = tf.cast(x_uint8, tf.float16)                  \n",
    "    x = tf.image.resize(x, TARGET_SIZE, method=\"bilinear\")\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a3a842-13f8-47bd-b867-84634fcbb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(H5_PATH, \"r\") as f:\n",
    "    X = f[\"images\"]  \n",
    "    y = f[\"ans\"]      \n",
    "    N = X.shape[0]\n",
    "\n",
    "    #infer embedding dim\n",
    "    d = int(encoder(preprocess_batch(X[0:1]), training=False).shape[-1])\n",
    "\n",
    "    emb_path = os.path.join(OUT_DIR, \"galaxy10_embeddings.dat\")\n",
    "    embeddings = np.memmap(emb_path, dtype=\"float32\", mode=\"w+\", shape=(N, d))\n",
    "    labels = np.zeros((N,), dtype=np.int64)\n",
    "\n",
    "    for i in range(0, N, BATCH):\n",
    "        xb = X[i:i+BATCH]\n",
    "        yb = y[i:i+BATCH]\n",
    "\n",
    "        xb = preprocess_batch(xb)\n",
    "        eb = encoder(xb, training=False).numpy().astype(\"float32\")\n",
    "\n",
    "        embeddings[i:i+len(eb)] = eb\n",
    "        labels[i:i+len(yb)] = yb\n",
    "\n",
    "    embeddings.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91039a4d-863e-4679-92f5-9a2c61da8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - artifacts/embeddings/galaxy10_embeddings.npy (17736, 48)\n",
      " - artifacts/embeddings/galaxy10_labels.npy (17736,)\n"
     ]
    }
   ],
   "source": [
    "emb_np = np.memmap(emb_path, dtype=\"float32\", mode=\"r\").reshape(-1, d)\n",
    "np.save(os.path.join(OUT_DIR, \"galaxy10_embeddings.npy\"), np.array(emb_np))\n",
    "np.save(os.path.join(OUT_DIR, \"galaxy10_labels.npy\"), labels)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - artifacts/embeddings/galaxy10_embeddings.npy\", emb_np.shape)\n",
    "print(\" - artifacts/embeddings/galaxy10_labels.npy\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959b5f5-3fec-4624-b213-9c9d00f7931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emb = np.load(\"artifacts/embeddings/galaxy10_embeddings.npy\")\n",
    "print(\"shape:\", emb.shape, \"dtype:\", emb.dtype)\n",
    "print(\"any NaNs:\", np.isnan(emb).any())\n",
    "print(\"mean/std:\", emb.mean(), emb.std())\n",
    "\n",
    "# mean = avg value of all embeddings dimensions across all samples\n",
    "# std = global spread (scale) of all embedding values\n",
    "# std less than 0.1 = collapsed / low-information embeddings\n",
    "# std greater than 5 or 10, unstable scale, distance explodes\n",
    "# 0.3-1.5 usually healthy\n",
    "# shape (17736, 48), 17736 = total images\n",
    "# 48 = 48 dimensional embedding vectors, so 48 numbers represent 1 galaxy \n",
    "# when clustering it compares each vector to one another to determine where it should go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3405aa5e-5e74-4c92-81ae-801c14f85854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model TARGET_SIZE: (256, 256)\n",
      "Manifest ok/exists files found: 200\n",
      "Already processed paths in new_inference: 400\n",
      "To embed (manifest - inference): 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 17:48:31.971814: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 48\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function preprocess_path at 0x7f49491d76a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function preprocess_path at 0x7f49491d76a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "embedded 48/200\n",
      "Saved:\n",
      " - artifacts/embeddings/new_embeddings.npy (200, 48)\n",
      " - artifacts/embeddings/new_labels.npy (200,)\n",
      " - artifacts/results/new_meta_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "#RUN TO CREATE EMBEDDINGS FOR NEW INPUTS ONLY\n",
    "#Need to run above cells if model has been changed\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "MANIFEST_CSV  = \"data/new_drop/manifest.csv\"                 # downloaded cutouts ledger\n",
    "INFERENCE_CSV = \"artifacts/results/new_inference.csv\"        # already processed by your pipeline\n",
    "\n",
    "MODEL_PATH = \"best_model/galaxy_b3_final_BEST_100TP.keras\"\n",
    "OUT_DIR = \"artifacts/embeddings\"\n",
    "META_OUT = \"artifacts/results/new_meta_embeddings.csv\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(META_OUT), exist_ok=True)\n",
    "\n",
    "#Load model + encoder\n",
    "clf = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "encoder = tf.keras.Model(clf.input, clf.layers[-2].output)\n",
    "\n",
    "#Infer target size from model input\n",
    "inp = encoder.input_shape\n",
    "TARGET_SIZE = (int(inp[1]), int(inp[2]))\n",
    "print(\"Model TARGET_SIZE:\", TARGET_SIZE)\n",
    "\n",
    "@tf.function\n",
    "def preprocess_path(path):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img_bytes, channels=3)\n",
    "    img = tf.image.resize(img, TARGET_SIZE, method=\"bilinear\")\n",
    "    img = tf.cast(img, tf.float32)  # keep 0..255\n",
    "    return img\n",
    "\n",
    "\n",
    "#Load manifest paths (downloaded)\n",
    "m = pd.read_csv(MANIFEST_CSV)\n",
    "if \"path\" not in m.columns:\n",
    "    raise ValueError(f\"{MANIFEST_CSV} must contain a 'path' column. Found: {list(m.columns)}\")\n",
    "\n",
    "m[\"path\"] = m[\"path\"].astype(str)\n",
    "\n",
    "#Keep only downloads taht were successful\n",
    "if \"status\" in m.columns:\n",
    "    ok_mask = m[\"status\"].astype(str).isin([\"ok\", \"exists\"])\n",
    "    m = m[ok_mask].copy()\n",
    "\n",
    "#Grab only unique paths\n",
    "manifest_paths = m[\"path\"].dropna().unique().tolist()\n",
    "#Make sure paths exist\n",
    "manifest_paths = [p for p in manifest_paths if os.path.exists(p)]\n",
    "\n",
    "print(\"Manifest ok/exists files found:\", len(manifest_paths))\n",
    "\n",
    "\n",
    "#Load already processed paths \n",
    "processed_paths = set()\n",
    "if os.path.exists(INFERENCE_CSV) and os.path.getsize(INFERENCE_CSV) > 0:\n",
    "    inf = pd.read_csv(INFERENCE_CSV)\n",
    "    if \"stored_path\" not in inf.columns:\n",
    "        raise ValueError(f\"{INFERENCE_CSV} must contain 'stored_path'. Found: {list(inf.columns)}\")\n",
    "    processed_paths = set(inf[\"stored_path\"].astype(str).dropna().unique().tolist())\n",
    "\n",
    "print(\"Already processed paths in new_inference:\", len(processed_paths))\n",
    "\n",
    "\n",
    "#Compute: manifest - inference\n",
    "processed_ids = {os.path.basename(p) for p in processed_paths}\n",
    "to_embed = [p for p in manifest_paths if os.path.basename(p) not in processed_ids]\n",
    "\n",
    "print(\"To embed (manifest - inference):\", len(to_embed))\n",
    "\n",
    "if len(to_embed) == 0:\n",
    "    print(\"Nothing new to embed. Exiting.\")\n",
    "    raise SystemExit\n",
    "\n",
    "M = len(to_embed)\n",
    "\n",
    "#infer embedding dim\n",
    "d = int(encoder(tf.zeros((1, *TARGET_SIZE, 3), dtype=tf.float32), training=False).shape[-1])\n",
    "print(\"Embedding dim:\", d)\n",
    "\n",
    "\n",
    "#Embed in batches\n",
    "emb = np.zeros((M, d), dtype=np.float32)\n",
    "\n",
    "for i in range(0, M, BATCH):\n",
    "    batch_paths = to_embed[i:i+BATCH]\n",
    "    xb = tf.stack([preprocess_path(pth) for pth in batch_paths], axis=0)\n",
    "    eb = encoder(xb, training=False).numpy().astype(\"float32\")\n",
    "    emb[i:i+len(eb)] = eb\n",
    "\n",
    "    if (i // BATCH) % 10 == 0:\n",
    "        print(f\"embedded {min(i+BATCH, M)}/{M}\")\n",
    "\n",
    "labels = np.full((M,), -1, dtype=np.int64)\n",
    "\n",
    "\n",
    "#Save outputs\n",
    "np.save(os.path.join(OUT_DIR, \"new_embeddings.npy\"), emb)\n",
    "np.save(os.path.join(OUT_DIR, \"new_labels.npy\"), labels)\n",
    "\n",
    "meta = pd.DataFrame({\"stored_path\": to_embed})\n",
    "meta.to_csv(META_OUT, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - artifacts/embeddings/new_embeddings.npy\", emb.shape)\n",
    "print(\" - artifacts/embeddings/new_labels.npy\", labels.shape)\n",
    "print(\" -\", META_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cf22f7-4cfc-4df9-83e7-324bfa84371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New embeddings this run: 200\n",
      "Unseen new embeddings to append: 200\n",
      "Saved:\n",
      " - artifacts/embeddings/embeddings_all.npy (18136, 48)\n",
      " - artifacts/embeddings/labels_all.npy (18136,)\n",
      " - artifacts/results/embeddings_all_meta.csv (18136, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = \"artifacts/embeddings\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "ALL_EMB = os.path.join(OUT_DIR, \"embeddings_all.npy\")\n",
    "ALL_LAB = os.path.join(OUT_DIR, \"labels_all.npy\")\n",
    "ALL_META = \"artifacts/results/embeddings_all_meta.csv\"\n",
    "\n",
    "#Load base galaxy10 \n",
    "emb_g10 = np.load(\"artifacts/embeddings/galaxy10_embeddings.npy\").astype(np.float32)\n",
    "y_g10   = np.load(\"artifacts/embeddings/galaxy10_labels.npy\").astype(np.int64)\n",
    "N0 = emb_g10.shape[0]\n",
    "\n",
    "#Load this run new\n",
    "emb_new = np.load(\"artifacts/embeddings/new_embeddings.npy\").astype(np.float32)\n",
    "meta_new = pd.read_csv(\"artifacts/results/new_meta_embeddings.csv\")\n",
    "assert len(meta_new) == emb_new.shape[0], \"new_meta_embeddings.csv must match new_embeddings rows\"\n",
    "\n",
    "#Use basename as identity \n",
    "new_ids = meta_new[\"stored_path\"].astype(str).map(os.path.basename).tolist()\n",
    "\n",
    "# If all files exist, load them; otherwise initialize from g10\n",
    "if os.path.exists(ALL_EMB) and os.path.exists(ALL_LAB) and os.path.exists(ALL_META):\n",
    "    emb_all = np.load(ALL_EMB).astype(np.float32)\n",
    "    y_all   = np.load(ALL_LAB).astype(np.int64)\n",
    "    meta_all = pd.read_csv(ALL_META)\n",
    "\n",
    "    #builds set of IDs that are already in enbeddings_all_meta\n",
    "    existing_new_ids = set(\n",
    "        meta_all[meta_all[\"source\"] == \"new\"][\"path\"].astype(str).map(os.path.basename).tolist()\n",
    "    )\n",
    "else:\n",
    "    emb_all = emb_g10\n",
    "    y_all   = y_g10\n",
    "    meta_all = pd.DataFrame({\n",
    "        \"row_id\": np.arange(N0),\n",
    "        \"source\": [\"galaxy10\"] * N0,\n",
    "        \"source_idx\": list(range(N0)),\n",
    "        \"path\": [\"<Galaxy10_DECals.h5>\"] * N0,\n",
    "        \"true_label\": y_g10,\n",
    "    })\n",
    "    existing_new_ids = set()\n",
    "\n",
    "\n",
    "#Keeps rows we have not processed before\n",
    "keep_mask = np.array([bid not in existing_new_ids for bid in new_ids], dtype=bool)\n",
    "k = int(keep_mask.sum())\n",
    "print(f\"New embeddings this run: {len(new_ids)}\")\n",
    "print(f\"Unseen new embeddings to append: {k}\")\n",
    "\n",
    "if k == 0:\n",
    "    print(\"Nothing new to append (all already present in embeddings_all).\")\n",
    "else:\n",
    "\n",
    "    emb_to_add = emb_new[keep_mask]\n",
    "    y_to_add = np.full((k,), -1, dtype=np.int64)\n",
    "    paths_to_add = meta_new[\"stored_path\"].astype(str).tolist()\n",
    "    paths_to_add = [p for p, keep in zip(paths_to_add, keep_mask) if keep]\n",
    "    \n",
    "    #Append arrays\n",
    "    emb_all = np.concatenate([emb_all, emb_to_add], axis=0)\n",
    "    y_all   = np.concatenate([y_all, y_to_add], axis=0)\n",
    "    \n",
    "    #Append meta rows\n",
    "    start = len(meta_all)\n",
    "    new_meta_rows = pd.DataFrame({\n",
    "        \"row_id\": np.arange(start, start + k),\n",
    "        \"source\": [\"new\"] * k,\n",
    "        \"source_idx\": list(range(k)),  # index within this appended chunk (fine)\n",
    "        \"path\": paths_to_add,\n",
    "        \"true_label\": y_to_add,\n",
    "    })\n",
    "    meta_all = pd.concat([meta_all, new_meta_rows], ignore_index=True)\n",
    "    \n",
    "    #Save\n",
    "    np.save(ALL_EMB, emb_all)\n",
    "    np.save(ALL_LAB, y_all)\n",
    "    meta_all.to_csv(ALL_META, index=False)\n",
    "    \n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", ALL_EMB, emb_all.shape)\n",
    "    print(\" -\", ALL_LAB, y_all.shape)\n",
    "    print(\" -\", ALL_META, meta_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac099a-06f4-4799-a226-aabfd8c46d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
