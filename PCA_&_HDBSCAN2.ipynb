{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8404d53-cbc0-4423-8455-bd1b1a215c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA (Principal Component Analysis) a way to compress and denoise embeddings by only keep the most important scalars in the vector\n",
    "#Lets say we have a 48 dimension vector, and we want to compress to 20. The PCA will create 20 new features that are a combination of the original 48\n",
    "\n",
    "#RUN ENTIRE FILE TO GET UPDATED CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f43d52-5900-4eb8-aac1-1575d9cbc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b29e02a-95bd-4822-a260-25a9401a22ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17736, 48) (17736,)\n"
     ]
    }
   ],
   "source": [
    "#Can use the below emb as it includes new images we processed without labels\n",
    "#But with model accuracy being only 82% it makes mores sense to just use galaxy10 for now\n",
    "# emb = np.load(\"artifacts/embeddings/embeddings_all.npy\")   #Comes from CreatingEmbeddings.ipynb\n",
    "emb = np.load(\"artifacts/embeddings/galaxy10_embeddings.npy\")\n",
    "y   = np.load(\"artifacts/embeddings/galaxy10_labels.npy\")       #Comes from CreatingEmbeddings.ipynb\n",
    "print(emb.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f658f5a8-b8bd-4dbe-8fb3-10ee342d99c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zp shape: (17736, 20) Explained variance: 0.9819521\n"
     ]
    }
   ],
   "source": [
    "OUT_MODELS = \"artifacts/models\"\n",
    "os.makedirs(OUT_MODELS, exist_ok=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(emb)\n",
    "\n",
    "pca = PCA(n_components=20, random_state=42)\n",
    "Zp = pca.fit_transform(Z)\n",
    "\n",
    "joblib.dump(scaler, f\"{OUT_MODELS}/scaler.pkl\")\n",
    "joblib.dump(pca, f\"{OUT_MODELS}/pca20.pkl\")\n",
    "\n",
    "print(\"Zp shape:\", Zp.shape, \"Explained variance:\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "#What is explained Variance? Explained Variance is how much of the information from the higher dimension was carried over during PCA.\n",
    "#This is why high variance is good, it tells us that a high amount of information was kept when compressing'\n",
    "#But even with high variance, it can still contain noise which can be seen in clustering.\n",
    "#In this case you can try and lower n_components even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4f5cc7-0ed7-47a8-8985-7fa3e17c24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 7\n",
      "Noise fraction: 0.3067207938655841\n",
      "Outlier proxy range: 0.0 0.6070280465052145\n"
     ]
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=60,\n",
    "    min_samples=10,\n",
    "    metric=\"euclidean\",\n",
    "    prediction_data=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(Zp)\n",
    "\n",
    "probs = clusterer.probabilities_   # membership probabilities\n",
    "\n",
    "#Outlier scores (higher = more outlier-like)\n",
    "outlier_scores = getattr(clusterer, \"outlier_scores_\", None)\n",
    "\n",
    "\n",
    "print(\"Clusters:\", len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0))\n",
    "print(\"Noise fraction:\", np.mean(cluster_labels == -1))\n",
    "print(\"Outlier proxy range:\", outlier_scores.min(), outlier_scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03f6ab9-a8d0-4eed-bf73-8d58b8cf5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered fraction: 0.643064228367529\n",
      "Mean prob (clustered): 0.8413363619732568\n",
      "Mean prob (noise): 0.0\n"
     ]
    }
   ],
   "source": [
    "labels = cluster_labels\n",
    "mask = labels != -1\n",
    "\n",
    "print(\"Clustered fraction:\", mask.mean()) #what percent of items are confidently assigned to some dense cluster)\n",
    "print(\"Mean prob (clustered):\", probs[mask].mean()) #Membership score (High score means most points are not borderline)\n",
    "print(\"Mean prob (noise):\", probs[~mask].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "314b79db-d6d9-46fb-9a91-f39b43dfb059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster  0: size=  182, mean_prob=0.918\n",
      "cluster  1: size= 1134, mean_prob=0.738\n",
      "cluster  2: size= 1293, mean_prob=0.771\n",
      "cluster  3: size= 5187, mean_prob=0.953\n",
      "cluster  4: size=  800, mean_prob=0.798\n",
      "cluster  5: size= 2000, mean_prob=0.672\n",
      "cluster  6: size=  938, mean_prob=0.832\n",
      "\n",
      "cluster_persistence_ (by label order in HDBSCAN):\n",
      "[0.06273125 0.2803693  0.19060551 0.08719951 0.10287783 0.19182774\n",
      " 0.09107706]\n"
     ]
    }
   ],
   "source": [
    "labels = cluster_labels\n",
    "mask = labels != -1\n",
    "\n",
    "#map each label to size + mean prob\n",
    "import numpy as np\n",
    "for lab in sorted(np.unique(labels[mask])):\n",
    "    idx = labels == lab\n",
    "    print(\n",
    "        f\"cluster {lab:>2}: size={idx.sum():>5}, \"\n",
    "        f\"mean_prob={probs[idx].mean():.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\ncluster_persistence_ (by label order in HDBSCAN):\")\n",
    "print(clusterer.cluster_persistence_)\n",
    "\n",
    "#higher persistence means the cluster exists over a wide range of density levels = very stable, likely a real structure\n",
    "# >0.30 = very strong, 0.10-0.20 = moderate. 0.05-0.10 = weak to moderate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ee4f1f9-2fe4-4e1b-b747-9a566062f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts/results/cluster_map.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>size</th>\n",
       "      <th>dominant_label</th>\n",
       "      <th>dominant_name</th>\n",
       "      <th>purity</th>\n",
       "      <th>top3_breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>4</td>\n",
       "      <td>Cigar</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>Cigar:0.947; In-between Round Smooth:0.018; Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1221</td>\n",
       "      <td>8</td>\n",
       "      <td>Edge-on (no bulge)</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>Edge-on (no bulge):0.982; Edge-on (with bulge)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1466</td>\n",
       "      <td>9</td>\n",
       "      <td>Edge-on (with bulge)</td>\n",
       "      <td>0.989768</td>\n",
       "      <td>Edge-on (with bulge):0.990; Edge-on (no bulge)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5685</td>\n",
       "      <td>7</td>\n",
       "      <td>Loose Spiral</td>\n",
       "      <td>0.343887</td>\n",
       "      <td>Loose Spiral:0.344; Barred Spiral:0.296; Tight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>Merging</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>Merging:0.971; Loose Spiral:0.017; In-between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1952</td>\n",
       "      <td>2</td>\n",
       "      <td>Round Smooth</td>\n",
       "      <td>0.944672</td>\n",
       "      <td>Round Smooth:0.945; Tight Spiral:0.028; In-bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>917</td>\n",
       "      <td>3</td>\n",
       "      <td>In-between Round Smooth</td>\n",
       "      <td>0.974918</td>\n",
       "      <td>In-between Round Smooth:0.975; Disturbed:0.010...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  size  dominant_label            dominant_name    purity  \\\n",
       "0           0   171               4                    Cigar  0.947368   \n",
       "1           1  1221               8       Edge-on (no bulge)  0.981982   \n",
       "2           2  1466               9     Edge-on (with bulge)  0.989768   \n",
       "3           3  5685               7             Loose Spiral  0.343887   \n",
       "4           4   884               1                  Merging  0.970588   \n",
       "5           5  1952               2             Round Smooth  0.944672   \n",
       "6           6   917               3  In-between Round Smooth  0.974918   \n",
       "\n",
       "                                      top3_breakdown  \n",
       "0  Cigar:0.947; In-between Round Smooth:0.018; Ba...  \n",
       "1  Edge-on (no bulge):0.982; Edge-on (with bulge)...  \n",
       "2  Edge-on (with bulge):0.990; Edge-on (no bulge)...  \n",
       "3  Loose Spiral:0.344; Barred Spiral:0.296; Tight...  \n",
       "4  Merging:0.971; Loose Spiral:0.017; In-between ...  \n",
       "5  Round Smooth:0.945; Tight Spiral:0.028; In-bet...  \n",
       "6  In-between Round Smooth:0.975; Disturbed:0.010...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add labels to each cluster run each time HDBScan is done\n",
    "#We only want to cluster using Galaxy10 as they have True Labels\n",
    "\n",
    "df = pd.read_csv(\"artifacts/results/galaxy10_clustered.csv\")\n",
    "df[df[\"source\"]==\"galaxy10\"]\n",
    "\n",
    "LABEL_NAMES  = [\n",
    "    \"Disturbed\", \"Merging\", \"Round Smooth\", \"In-between Round Smooth\", \"Cigar\",\n",
    "    \"Barred Spiral\", \"Tight Spiral\", \"Loose Spiral\", \"Edge-on (no bulge)\", \"Edge-on (with bulge)\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for cid in sorted([c for c in df.cluster_id.unique() if c != -1]):\n",
    "    sub = df[df.cluster_id == cid]\n",
    "\n",
    "    # dominant class + purity\n",
    "    vc = sub.true_label.value_counts(normalize=True)\n",
    "    dom_label = int(vc.index[0])\n",
    "    purity = float(vc.iloc[0])\n",
    "\n",
    "    # top-3 breakdown (nice to keep)\n",
    "    top3 = sub.true_label.value_counts(normalize=True).head(3)\n",
    "    top3_str = \"; \".join([f\"{LABEL_NAMES[int(k)]}:{v:.3f}\" for k, v in top3.items()])\n",
    "\n",
    "    rows.append({\n",
    "        \"cluster_id\": int(cid),\n",
    "        \"size\": int(len(sub)),\n",
    "        \"dominant_label\": dom_label,\n",
    "        \"dominant_name\": LABEL_NAMES[dom_label],\n",
    "        \"purity\": purity,\n",
    "        \"top3_breakdown\": top3_str,\n",
    "    })\n",
    "\n",
    "cluster_map_df = pd.DataFrame(rows).sort_values(\"cluster_id\")\n",
    "cluster_map_df.to_csv(\"artifacts/results/cluster_map.csv\", index=False)\n",
    "\n",
    "print(\"Saved artifacts/results/cluster_map.csv\")\n",
    "cluster_map_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "defd6ef7-2aef-468e-82b4-56ed7ffce839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts/results/combined_clustered.csv (17936, 7)\n"
     ]
    }
   ],
   "source": [
    "N0 = 17736                  #Galaxy10 count\n",
    "N  = len(cluster_labels)\n",
    "N_new = N - N0\n",
    "\n",
    "y0 = np.asarray(y).astype(np.int64)\n",
    "y_all = np.concatenate([y0, np.full(N_new, -1, dtype=np.int64)])\n",
    "\n",
    "source = np.array([\"galaxy10\"] * N0 + [\"new\"] * N_new, dtype=object)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"row_id\": np.arange(N, dtype=np.int32),\n",
    "    \"source\": source,\n",
    "    \"true_label\": y_all,\n",
    "    \"cluster_id\": np.asarray(cluster_labels, dtype=np.int32),\n",
    "    \"membership_prob\": np.asarray(probs, dtype=np.float32),\n",
    "    \"outlier_score\": (1.0 - np.asarray(probs, dtype=np.float32)),\n",
    "})\n",
    "\n",
    "#Path mapping for new rows\n",
    "meta_new = pd.read_csv(\"artifacts/results/new_meta_embeddings.csv\")\n",
    "\n",
    "paths = np.array([\"<Galaxy10_DECals.h5>\"] * N0 + meta_new[\"stored_path\"].astype(str).tolist(), dtype=object)\n",
    "df[\"path\"] = paths\n",
    "\n",
    "os.makedirs(\"artifacts/results\", exist_ok=True)\n",
    "df.to_csv(\"artifacts/results/combined_clustered.csv\", index=False)\n",
    "print(\"Saved artifacts/results/combined_clustered.csv\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54162892-79fb-4d8f-8101-39549794bac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 (n=171):\n",
      "true_label\n",
      "4    0.947368\n",
      "3    0.017544\n",
      "5    0.017544\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 1 (n=1221):\n",
      "true_label\n",
      "8    0.981982\n",
      "9    0.013923\n",
      "7    0.001638\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 2 (n=1466):\n",
      "true_label\n",
      "9    0.989768\n",
      "8    0.008186\n",
      "7    0.002046\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 3 (n=5685):\n",
      "true_label\n",
      "7    0.343887\n",
      "5    0.296394\n",
      "6    0.243272\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 4 (n=884):\n",
      "true_label\n",
      "1    0.970588\n",
      "7    0.016968\n",
      "3    0.004525\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 5 (n=1952):\n",
      "true_label\n",
      "2    0.944672\n",
      "6    0.027664\n",
      "3    0.009734\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cluster 6 (n=917):\n",
      "true_label\n",
      "3    0.974918\n",
      "0    0.009815\n",
      "1    0.005453\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"artifacts/results/combined_clustered.csv\")\n",
    "df[df[\"source\"] == \"galaxy10\"]\n",
    "\n",
    "#For each cluster: what label dominates\n",
    "for cid in sorted([c for c in df.cluster_id.unique() if c != -1]):\n",
    "    sub = df[df.cluster_id == cid]\n",
    "    top = sub.true_label.value_counts(normalize=True).head(3)\n",
    "    print(f\"\\nCluster {cid} (n={len(sub)}):\")\n",
    "    print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1083967-9e79-4262-9e4a-ce3d2a029474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
